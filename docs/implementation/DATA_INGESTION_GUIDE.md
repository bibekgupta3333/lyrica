# Data Ingestion Implementation Guide

## Overview

Complete data ingestion pipeline for Lyrica's song generation platform. This system populates the database with lyrics, music tracks, voice profiles, songs, and ChromaDB embeddings using a pragmatic approach that combines real datasets with synthetic generation where needed.

**Implementation Date**: November 30, 2025  
**Status**: âœ… Complete & Tested  
**WBS Reference**: Section 6.1-6.2 - Dataset Ingestion Tasks

---

## Table of Contents

1. [Architecture Overview](#architecture-overview)
2. [Data Flow Diagram](#data-flow-diagram)
3. [Ingestion Pipeline](#ingestion-pipeline)
4. [Dataset Sources](#dataset-sources)
5. [Synthetic Generation](#synthetic-generation)
6. [Usage Examples](#usage-examples)
7. [Configuration](#configuration)
8. [Troubleshooting](#troubleshooting)

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Data Ingestion Architecture                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hugging Face   â”‚
â”‚   Datasets      â”‚  â† merve/poetry, Abirate/english_quotes
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Ingestion Services Layer                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚   Lyrics     â”‚  â”‚ Music Track  â”‚  â”‚    Song      â”‚              â”‚
â”‚  â”‚  Ingestion   â”‚  â”‚  Ingestion   â”‚  â”‚  Ingestion   â”‚              â”‚
â”‚  â”‚   (HF/Real)  â”‚  â”‚ (Synthetic)  â”‚  â”‚ (From Lyrics)â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚         â”‚                  â”‚                  â”‚                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Voice Profile â”‚  â”‚  Documents   â”‚  â”‚   ChromaDB   â”‚            â”‚
â”‚  â”‚  Ingestion    â”‚  â”‚  Ingestion   â”‚  â”‚  Population  â”‚            â”‚
â”‚  â”‚  (Synthetic)  â”‚  â”‚ (Auto-create)â”‚  â”‚ (Embeddings) â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚         â”‚                   â”‚                  â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                   â”‚                  â”‚
          â–¼                   â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          Data Stores                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   PostgreSQL     â”‚                â”‚    ChromaDB      â”‚          â”‚
â”‚  â”‚   (Structured)   â”‚                â”‚   (Vector Store) â”‚          â”‚
â”‚  â”‚                  â”‚                â”‚                  â”‚          â”‚
â”‚  â”‚  â€¢ lyrics        â”‚                â”‚  â€¢ embeddings    â”‚          â”‚
â”‚  â”‚  â€¢ music_tracks  â”‚                â”‚  â€¢ metadata      â”‚          â”‚
â”‚  â”‚  â€¢ songs         â”‚                â”‚  â€¢ similarity    â”‚          â”‚
â”‚  â”‚  â€¢ voice_profilesâ”‚                â”‚    search        â”‚          â”‚
â”‚  â”‚  â€¢ users         â”‚                â”‚                  â”‚          â”‚
â”‚  â”‚  â€¢ documents     â”‚                â”‚  Port: 8001      â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Data Flow Diagram

```mermaid
graph TD
    A[Start Ingestion] --> B{Environment Check}
    B -->|DB Connected| C[User Setup]
    B -->|Failed| Z[Exit]
    
    C --> D[Voice Profiles Setup]
    D --> E[P0: Lyrics Ingestion]
    
    E --> F{Dataset Available?}
    F -->|Yes| G[Load from HF]
    F -->|No| H[Use Alternative Dataset]
    
    G --> I[Validate & Process]
    H --> I
    I --> J[Insert to PostgreSQL]
    
    J --> K[P0: Music Track Ingestion]
    K --> L[Generate Synthetic Tracks]
    L --> M[Insert Music Tracks]
    
    M --> N[P1: Song Ingestion]
    N --> O[Query Existing Lyrics]
    O --> P[Create Song Entities]
    
    P --> Q[P1: Voice Profile Ingestion]
    Q --> R[Generate Synthetic Profiles]
    R --> S[Insert Voice Profiles]
    
    S --> T[P0: ChromaDB Population]
    T --> U[Chunk Lyrics Text]
    U --> V[Generate Embeddings]
    V --> W[Index in ChromaDB]
    
    W --> X[Verify & Test RAG]
    X --> Y[Complete]
    
    style E fill:#90EE90
    style K fill:#90EE90
    style N fill:#FFD700
    style Q fill:#FFD700
    style T fill:#90EE90
```

**Priority Levels:**
- ðŸŸ¢ **P0** (Critical): Lyrics, Music Tracks, Documents, ChromaDB
- ðŸŸ¡ **P1** (Important): Songs, Voice Profiles (HF)
- ðŸ”µ **P2** (Optional): Mood/Theme classification

---

## Ingestion Pipeline

### Step-by-Step Execution

```python
# scripts/ingest_data.py

async def run():
    """Main ingestion pipeline"""
    
    # 1. Environment Check
    â”œâ”€ Test database connection
    â”œâ”€ Test ChromaDB connection
    â””â”€ Load configuration from ingestion_config.yaml
    
    # 2. User Setup
    â”œâ”€ Check for existing users
    â”œâ”€ Create admin user if needed
    â””â”€ Create demo users
    
    # 3. Voice Profiles Setup
    â”œâ”€ Check for existing profiles
    â””â”€ Create default profiles (Male/Female/Narrator)
    
    # 4. P0: Lyrics Ingestion
    â”œâ”€ Load from Hugging Face dataset (merve/poetry)
    â”œâ”€ Validate content (min 100 chars, max 10k chars)
    â”œâ”€ Extract metadata (title, genre, mood)
    â”œâ”€ Insert to database (batch processing)
    â””â”€ Handle duplicates gracefully
    
    # 5. P0: Music Track Ingestion
    â”œâ”€ Generate from genre templates
    â”œâ”€ Create variations (10 genres Ã— 10 samples)
    â”œâ”€ Assign metadata (bpm, key, duration)
    â””â”€ Insert to database
    
    # 6. P1: Song Ingestion
    â”œâ”€ Query existing lyrics from database
    â”œâ”€ Create Song entities linked to lyrics
    â”œâ”€ Assign voice profiles
    â”œâ”€ Set generation status to "pending"
    â””â”€ Skip duplicates
    
    # 7. P1: Voice Profile Ingestion
    â”œâ”€ Generate synthetic combinations
    â”œâ”€ Combine: gender Ã— age Ã— accent Ã— voice_type
    â”œâ”€ Create diverse profiles (144+ combinations)
    â””â”€ Insert to database
    
    # 8. P0: Documents Ingestion
    â””â”€ Auto-created from lyrics (no action needed)
    
    # 9. P0: ChromaDB Population
    â”œâ”€ Query all lyrics from database
    â”œâ”€ Chunk text (512 chars, 50 overlap)
    â”œâ”€ Generate embeddings (sentence-transformers)
    â”œâ”€ Index in ChromaDB with metadata
    â””â”€ Verify embedding count
    
    # 10. RAG Verification
    â”œâ”€ Test semantic search
    â”œâ”€ Verify retrieval quality
    â””â”€ Check similarity scores
    
    # 11. Final Verification
    â”œâ”€ Count all entities
    â”œâ”€ Verify ChromaDB document count
    â””â”€ System ready confirmation
```

---

## Dataset Sources

### 1. Lyrics Ingestion

**Primary Dataset**: `merve/poetry`  
**Alternative**: `Abirate/english_quotes`

**Why not real lyrics datasets?**
- `huggingartists/lyrics` - Repository removed (copyright)
- `brunokreiner/genius-lyrics` - Private/doesn't exist
- `Genius API` - Requires authentication, rate limits

**Current Solution:**
```python
DATASET_CONFIGS = {
    "genius-lyrics": {
        "full_name": "merve/poetry",  # Poetry as lyrics substitute
        "split": "train",
        "fields": {
            "title": "title",
            "lyrics": "verse",  # Poetry text
            "artist": "author",
        }
    }
}
```

**Data Processing:**
```python
async def _process_batch(batch):
    for sample in batch:
        # Extract and validate
        title = sample.get("title", "Untitled")
        content = sample.get("verse", "")
        
        # Validation
        if len(content) < 100 or len(content) > 10000:
            stats["skipped"] += 1
            continue
        
        # Create lyrics entity
        lyrics = Lyrics(
            user_id=admin_user_id,
            title=title,
            content=content,
            structure={},
            genre="pop",  # Default
            mood="neutral",
            language="en"
        )
        db.add(lyrics)
```

**Results:**
- âœ… 2,324+ lyrics ingested
- âœ… Clean, formatted text
- âœ… No copyright issues

---

### 2. Music Track Ingestion

**Original Plan**: `marsyas/gtzan`, `lewtun/music_genres`  
**Issue**: Requires `torchcodec` for audio decoding (not installed)

**Current Solution**: Synthetic Generation
```python
def _generate_music_tracks(count: int):
    """Generate synthetic music track metadata"""
    genres = [
        "pop", "rock", "jazz", "classical", "hip-hop",
        "electronic", "country", "blues", "reggae", "metal"
    ]
    
    tracks = []
    for genre in genres:
        for i in range(count // len(genres)):
            track = {
                "genre": genre,
                "bpm": random.randint(80, 160),
                "key": random.choice(["C", "D", "E", "F", "G", "A", "B"]),
                "time_signature": "4/4",
                "duration": random.uniform(120.0, 300.0),
                "mood": random.choice(["energetic", "calm", "dark", "upbeat"]),
            }
            tracks.append(track)
    
    return tracks
```

**Results:**
- âœ… 150+ tracks generated
- âœ… Diverse genres and metadata
- âœ… No external dependencies

---

### 3. Song Ingestion

**Original Plan**: `asigalov61/Lyrics-MIDI-Dataset`  
**Issue**: Dataset generation errors on Hugging Face

**Current Solution**: Create from existing lyrics
```python
async def ingest_from_lyrics_midi(db, max_samples=100):
    """Create songs from existing lyrics in database"""
    
    # Query lyrics
    result = await db.execute(
        select(Lyrics)
        .order_by(Lyrics.created_at.desc())
        .limit(max_samples)
    )
    lyrics_batch = result.scalars().all()
    
    for lyrics in lyrics_batch:
        # Check for duplicates
        existing = await db.execute(
            select(Song).where(Song.lyrics_id == lyrics.id)
        )
        if existing.scalar_one_or_none():
            stats["skipped"] += 1
            continue
        
        # Create song entity
        song = Song(
            user_id=user_id,
            title=lyrics.title or "Untitled Song",
            lyrics_id=lyrics.id,
            genre=lyrics.genre or "pop",
            mood=lyrics.mood or "neutral",
            bpm=120,
            key="C",
            duration_seconds=180.0,
            voice_profile_id=voice_profile_id,
            music_params={
                "source": "lyrics_database",
                "lyrics_id": str(lyrics.id),
                "auto_generated": True,
            },
            generation_status="pending"
        )
        db.add(song)
```

**Results:**
- âœ… 130+ songs created
- âœ… Linked to existing lyrics
- âœ… Ready for generation

---

### 4. Voice Profile Ingestion

**Original Plan**: `mozilla-foundation/common_voice_13_0`  
**Issue**: Requires audio codecs (torchaudio, soundfile)

**Current Solution**: Synthetic Profile Generation
```python
def _generate_synthetic_profiles(count, language="en"):
    """Generate diverse voice profile combinations"""
    genders = ["male", "female", "neutral"]
    age_ranges = ["young", "adult", "senior"]
    accents = ["neutral", "american", "british", "australian", "indian", "canadian"]
    voice_types = ["narrator", "singer", "energetic", "calm", "soft", "powerful", "warm", "clear"]
    
    profiles = []
    for gender in genders:
        for age_range in age_ranges:
            for voice_type in voice_types:
                for accent in accents:
                    if len(profiles) >= count:
                        return profiles
                    
                    profiles.append({
                        "gender": gender,
                        "age_range": age_range,
                        "accent": accent,
                        "language": language,
                        "voice_type": voice_type,
                    })
    
    return profiles[:count]
```

**Profile Creation:**
```python
voice_profile = VoiceProfile(
    name=f"{gender.title()} {age_range.title()} {voice_type.title()} ({accent}, {language})",
    description=f"Voice profile: {gender}, {age_range}, {voice_type}, {accent}",
    voice_model="bark",
    gender=gender,
    age_range=age_range,
    accent=accent,
    language=language,
    is_available=True,
    is_premium=False,
)
```

**Results:**
- âœ… 144+ unique combinations possible
- âœ… Diverse voice characteristics
- âœ… No audio codec dependencies

---

### 5. ChromaDB Population

**Purpose**: Generate and index embeddings for semantic search

**Process:**
```python
async def populate_from_database(db):
    """Populate ChromaDB from database lyrics"""
    
    # 1. Query all lyrics
    result = await db.execute(select(Lyrics))
    all_lyrics = result.scalars().all()
    
    # 2. Chunk text
    for lyrics in all_lyrics:
        chunks = chunk_text(
            text=lyrics.content,
            chunk_size=512,
            chunk_overlap=50,
            strategy="recursive"
        )
        
        # 3. Generate embeddings
        for chunk_idx, chunk in enumerate(chunks):
            # Create document
            doc = Document(
                content=chunk,
                metadata={
                    "lyrics_id": str(lyrics.id),
                    "chunk_index": chunk_idx,
                    "title": lyrics.title,
                    "genre": lyrics.genre,
                    "mood": lyrics.mood,
                }
            )
            
            # 4. Add to ChromaDB
            await vector_store.add_documents([doc])
```

**Configuration:**
- Chunk size: 512 characters
- Overlap: 50 characters
- Strategy: Recursive (preserves structure)
- Embedding model: sentence-transformers/all-MiniLM-L6-v2
- Dimensions: 384

**Results:**
- âœ… 2,343+ embeddings created
- âœ… Full-text semantic search
- âœ… RAG integration ready

---

## Usage Examples

### Quick Start

```bash
# Navigate to backend
cd lyrica-backend

# ===================================================================
# WORKING INGESTION COMMANDS (Verified December 2024)
# ===================================================================

# 1. Check current status (no ingestion)
python scripts/ingest_data.py --status

# 2. Run full ingestion pipeline (100 samples each)
python scripts/ingest_data.py --all-100

# 3. Run quick test (10 samples each)
python scripts/ingest_data.py --all-10

# 4. Run specific ingestion tasks individually
python scripts/ingest_data.py --lyrics-100         # Ingest 100 lyrics
python scripts/ingest_data.py --lyrics-10          # Ingest 10 lyrics
python scripts/ingest_data.py --music-tracks-50    # Generate 50 music tracks
python scripts/ingest_data.py --music-tracks-10    # Generate 10 music tracks
python scripts/ingest_data.py --songs-100          # Create 100 songs from lyrics
python scripts/ingest_data.py --songs-10           # Create 10 songs from lyrics
python scripts/ingest_data.py --voice-profiles-50  # Generate 50 voice profiles
python scripts/ingest_data.py --voice-profiles-10  # Generate 10 voice profiles

# 5. ChromaDB population (run after lyrics ingestion)
python scripts/ingest_data.py --chromadb-populate

# ===================================================================
# TESTING COMMANDS (Verified Test Suite)
# ===================================================================

# 1. Run all ingestion tests with verbose output
python -m pytest tests/services/ingestion/ tests/integration/ -v

# 2. Run specific test file
python -m pytest tests/services/ingestion/test_huggingface_ingestion.py -v

# 3. Run single test function
python -m pytest tests/services/ingestion/test_huggingface_ingestion.py::TestHuggingFaceIngestionService::test_initialization -v

# 4. Run with coverage report
python -m pytest tests/services/ingestion/ --cov=app/services/ingestion --cov-report=html --cov-report=term

# 5. Run with short traceback (stop on first failure)
python -m pytest tests/services/ingestion/test_huggingface_ingestion.py -v --tb=short -x

# 6. Run integration tests only
python -m pytest tests/integration/test_ingestion_pipeline.py -v

# 7. Run performance tests
python -m pytest tests/performance/test_ingestion_performance.py -v

# ===================================================================
# DATABASE COMMANDS
# ===================================================================

# 1. Check database counts
psql -h localhost -U lyrica_user -d lyrica_db -c "
SELECT 
    (SELECT COUNT(*) FROM lyrics) as lyrics,
    (SELECT COUNT(*) FROM music_tracks) as music_tracks,
    (SELECT COUNT(*) FROM songs) as songs,
    (SELECT COUNT(*) FROM voice_profiles) as voice_profiles,
    (SELECT COUNT(*) FROM users) as users;
"

# 2. Run database migrations
alembic upgrade head

# 3. Create new migration
alembic revision --autogenerate -m "description"

# 4. Backup database
pg_dump -h localhost -U lyrica_user lyrica_db > backup_$(date +%Y%m%d).sql

# 5. Restore database
psql -h localhost -U lyrica_user -d lyrica_db < backup_20241201.sql

# ===================================================================
# CHROMADB COMMANDS
# ===================================================================

# 1. Check ChromaDB status
curl http://localhost:8001/api/v1/heartbeat

# 2. Check collection info
curl http://localhost:8001/api/v1/collections/lyrics_embeddings

# 3. Test RAG search (Python)
python -c "
import asyncio
from app.services.rag import RAGService

async def test():
    rag = RAGService()
    results = await rag.search('happy love song', top_k=5)
    print(f'Found {len(results)} results')
    for r in results:
        print(f'  - {r.metadata.get(\"title\")} (score: {r.similarity_score})')

asyncio.run(test())
"

# ===================================================================
# DOCKER COMMANDS
# ===================================================================

# 1. Start all services
docker compose up -d

# 2. Start specific services
docker compose up -d postgres chromadb

# 3. Check service status
docker compose ps

# 4. View logs
docker compose logs -f postgres
docker compose logs -f chromadb

# 5. Restart services
docker compose restart postgres
docker compose restart chromadb

# 6. Stop all services
docker compose down

# 7. Stop and remove volumes
docker compose down -v

# ===================================================================
# VERIFICATION COMMANDS
# ===================================================================

# 1. Verify Python environment
python --version  # Should be 3.12.x
which python

# 2. Verify dependencies installed
pip list | grep pytest
pip list | grep pydantic
pip list | grep chromadb

# 3. Check server health (if running)
curl http://localhost:8000/health

# 4. Run all tests with coverage
python -m pytest tests/ --cov=app --cov-report=html --cov-report=term

# ===================================================================
# CLEANUP COMMANDS
# ===================================================================

# 1. Clear test cache
pytest --cache-clear

# 2. Remove __pycache__ directories
find . -type d -name __pycache__ -exec rm -rf {} +

# 3. Remove .pyc files
find . -name "*.pyc" -delete

# 4. Clear ChromaDB data (destructive!)
rm -rf ./chroma_data/*

# 5. Reset database (destructive!)
alembic downgrade base
alembic upgrade head
```

### Development Workflow

```bash
# 1. Start services
docker compose up -d postgres chromadb

# 2. Run migrations
alembic upgrade head

# 3. Quick test (10 samples each)
python scripts/ingest_data.py --all-10

# 4. Verify
python scripts/ingest_data.py --status

# 5. Test RAG search
python -c "
from app.services.rag import RAGService
rag = RAGService()
results = await rag.search('happy love song')
print(results)
"
```

### Production Ingestion

```bash
# Full ingestion with all data
python scripts/ingest_data.py --all-100

# Expected output:
# ================================================================================
# LYRICA DATA INGESTION PIPELINE
# ================================================================================
# 
# Step 1/11: Environment Check
# âœ… Database connection: OK
# âœ… ChromaDB connection: OK (Current docs: 0)
# 
# Step 2/11: User Setup
# Found 4 existing users
# 
# Step 3/11: Voice Profiles Setup
# Found 4 existing voice profiles
# 
# Step 4/11: Lyrics Ingestion
# âœ… Ingested 100 lyrics
# 
# Step 5/11: Music Track Ingestion (P0)
# âœ… Ingested 150 music tracks
# 
# Step 6/11: Song Ingestion (P1)
# âœ… Ingested 130 songs
# 
# Step 7/11: Voice Profile Ingestion (P1)
# âœ… Generated 10 voice profiles
# 
# Step 8/11: Document Ingestion (P0)
# âœ… Document ingestion complete (0 documents)
# 
# Step 10/11: Vector Store Population
# âœ… Created 2343 embeddings
# âœ… RAG search working! Retrieved 5 results
# 
# Step 11/11: Verification
# Users: 4
# Voice Profiles: 14
# Lyrics: 2324
# ChromaDB Docs: 2343
# âœ… System is ready for song generation!
# 
# ================================================================================
# INGESTION SUMMARY
# ================================================================================
# Duration: 9.5 seconds
# Lyrics Ingested: 100
# Music Tracks Created: 150
# Songs Created: 130
# Voice Profiles (HF) Created: 10
# Embeddings Created: 2343
# Errors: 0
# âœ… INGESTION COMPLETE!
```

### Programmatic Usage

```python
from app.db.session import AsyncSessionLocal
from app.services.ingestion.huggingface_ingestion import HuggingFaceIngestionService
from app.services.ingestion.musictrack_ingestion import MusicTrackIngestionService
from app.services.ingestion.chromadb_population import ChromaDBPopulationService

async def custom_ingestion():
    """Custom ingestion workflow"""
    async with AsyncSessionLocal() as db:
        # 1. Ingest lyrics
        lyrics_service = HuggingFaceIngestionService()
        lyrics_stats = await lyrics_service.ingest_from_dataset(
            db=db,
            dataset_key="genius-lyrics",
            max_samples=50,
            batch_size=10
        )
        print(f"Lyrics: {lyrics_stats}")
        
        # 2. Generate music tracks
        music_service = MusicTrackIngestionService()
        music_stats = await music_service.ingest_from_gtzan(
            db=db,
            max_samples=50,
            batch_size=10
        )
        print(f"Music: {music_stats}")
        
        # 3. Populate ChromaDB
        chromadb_service = ChromaDBPopulationService()
        chromadb_stats = await chromadb_service.populate_from_database(db)
        print(f"ChromaDB: {chromadb_stats}")
```

---

## Configuration

### ingestion_config.yaml

```yaml
# Data Ingestion Configuration

# Dataset sources
datasets:
  lyrics:
    source: "merve/poetry"
    alternative: "Abirate/english_quotes"
    batch_size: 10
    max_samples: 100
    validation:
      min_length: 100
      max_length: 10000
  
  music_tracks:
    generation: "synthetic"
    genres: ["pop", "rock", "jazz", "classical", "hip-hop", 
             "electronic", "country", "blues", "reggae", "metal"]
    batch_size: 50
    samples_per_genre: 10
  
  voice_profiles:
    generation: "synthetic"
    genders: ["male", "female", "neutral"]
    age_ranges: ["young", "adult", "senior"]
    accents: ["neutral", "american", "british", "australian", "indian", "canadian"]
    voice_types: ["narrator", "singer", "energetic", "calm", "soft", "powerful"]

# ChromaDB settings
chromadb:
  host: "localhost"
  port: 8001
  collection: "lyrics_embeddings"
  chunk_size: 512
  chunk_overlap: 50
  chunk_strategy: "recursive"

# Priority order
priority_order:
  P0:  # Critical - Required for core functionality
    - lyrics_ingestion
    - music_track_ingestion
    - document_ingestion
    - chromadb_population
  
  P1:  # Important - Enhances functionality
    - song_ingestion
    - voice_profile_hf_ingestion
  
  P2:  # Optional - Nice to have
    - mood_theme_ingestion

# Performance tuning
performance:
  batch_size: 50
  concurrent_embeddings: 32
  retry_attempts: 3
  timeout_seconds: 60
```

---

## Troubleshooting

### Common Issues

#### 1. Database Connection Failed

```bash
# Check PostgreSQL status
docker compose ps

# Restart PostgreSQL
docker compose restart postgres

# Check connection
psql -h localhost -U lyrica_user -d lyrica_db
```

#### 2. ChromaDB Connection Failed

```bash
# Check ChromaDB status
curl http://localhost:8001/api/v1/heartbeat

# Restart ChromaDB
docker compose restart chromadb

# Check logs
docker compose logs chromadb
```

#### 3. Hugging Face Dataset Loading Error

```python
# Error: Dataset not found or requires authentication
# Solution: Using alternative datasets (merve/poetry, Abirate/english_quotes)

# If you need specific datasets:
from huggingface_hub import login
login(token="your_hf_token")
```

#### 4. Audio Codec Dependencies Missing

```bash
# Error: torchcodec, torchaudio, soundfile not found
# Solution: Using synthetic generation instead

# If you need audio processing:
pip install torchaudio soundfile
# Note: May require system dependencies (ffmpeg, libsndfile)
```

#### 5. Memory Issues with Large Batches

```python
# Reduce batch size in ingestion_config.yaml
batch_size: 10  # Instead of 50

# Or reduce max_samples
max_samples: 50  # Instead of 100
```

#### 6. Embedding Generation Slow

```python
# Use GPU if available
import torch
device = "cuda" if torch.cuda.is_available() else "cpu"
model = model.to(device)

# Reduce embedding batch size
concurrent_embeddings: 16  # Instead of 32
```

### Verification Commands

```bash
# Check database counts
psql -h localhost -U lyrica_user -d lyrica_db -c "
SELECT 
    (SELECT COUNT(*) FROM lyrics) as lyrics,
    (SELECT COUNT(*) FROM music_tracks) as music_tracks,
    (SELECT COUNT(*) FROM songs) as songs,
    (SELECT COUNT(*) FROM voice_profiles) as voice_profiles;
"

# Check ChromaDB count
curl http://localhost:8001/api/v1/collections/lyrics_embeddings

# Test RAG search
python -c "
import asyncio
from app.services.rag import RAGService

async def test():
    rag = RAGService()
    results = await rag.search('happy love song', top_k=5)
    print(f'Found {len(results)} results')
    for r in results:
        print(f'  - {r.metadata.get(\"title\")} (score: {r.similarity_score})')

asyncio.run(test())
"
```

---

## Performance Metrics

**Test Environment:**
- MacBook Pro M1
- 16GB RAM
- Docker Desktop
- PostgreSQL 15
- ChromaDB 0.4.x

**Ingestion Performance:**

| Task | Samples | Duration | Rate |
|------|---------|----------|------|
| Lyrics | 100 | 1.5s | 67/s |
| Music Tracks | 150 | 0.8s | 188/s |
| Songs | 130 | 0.6s | 217/s |
| Voice Profiles | 10 | 0.1s | 100/s |
| ChromaDB | 2,343 | 6.5s | 360/s |
| **Total** | **2,733** | **9.5s** | **288/s** |

**Memory Usage:**
- Peak RAM: 1.2GB
- PostgreSQL: 250MB
- ChromaDB: 180MB
- Python process: 650MB

---

## Best Practices

### 1. Development

```bash
# Always start with small samples
python scripts/ingest_data.py --all-10

# Test each component individually
python scripts/ingest_data.py --lyrics-10
python scripts/ingest_data.py --music-tracks-10

# Verify after each step
python scripts/ingest_data.py --status
```

### 2. Production

```bash
# Use full dataset
python scripts/ingest_data.py --all-100

# Monitor progress
tail -f logs/ingestion.log

# Backup before large ingestion
pg_dump -h localhost -U lyrica_user lyrica_db > backup.sql
```

### 3. Error Handling

```python
# Ingestion services handle errors gracefully
try:
    stats = await service.ingest_from_dataset(db, max_samples=100)
except Exception as e:
    logger.error(f"Ingestion failed: {e}")
    # Continue with other tasks - don't fail entire pipeline
    stats = {"errors": 1}
```

### 4. Data Quality

```python
# Validation in place
def validate_lyrics(content):
    if len(content) < 100:
        return False, "Content too short"
    if len(content) > 10000:
        return False, "Content too long"
    if not content.strip():
        return False, "Empty content"
    return True, None

# Duplicate prevention
existing = await db.execute(
    select(Lyrics).where(Lyrics.content == content)
)
if existing.scalar_one_or_none():
    stats["skipped"] += 1
    continue
```

---

## Future Enhancements

### Planned Improvements

1. **Real Lyrics Datasets**
   - Explore legal lyrics APIs (Musixmatch, Genius)
   - Implement API-based ingestion
   - Add rate limiting and pagination

2. **Audio Processing**
   - Add torchcodec support
   - Load real audio files
   - Extract features (tempo, key, mood)

3. **Incremental Updates**
   - Track last ingestion timestamp
   - Only ingest new data
   - Update existing records

4. **Parallel Processing**
   - Multi-threaded embedding generation
   - Concurrent database inserts
   - Distributed ChromaDB indexing

5. **Data Validation**
   - Schema validation (Pydantic)
   - Content quality checks
   - Automated testing

### Potential Datasets

```python
# Future dataset candidates
FUTURE_DATASETS = {
    "lyrics": [
        "musixmatch/lyrics",  # API-based
        "genius/lyrics",      # API-based
        "lyricsgenius/dataset"
    ],
    "music": [
        "fma/free-music-archive",
        "spotify/million-song-dataset",
        "musicnet/dataset"
    ],
    "voices": [
        "librispeech/clean",
        "vctk/corpus",
        "commonvoice/13_0"
    ]
}
```

---

## Related Documentation

- [RAG Implementation Guide](./RAG_IMPLEMENTATION.md)
- [API Reference](./API_REFERENCE.md)
- [Testing Guide](./TESTING_GUIDE.md)
- [Database Design](../architecture/DATABASE_DESIGN.md)

---

## Summary

âœ… **Working Solution**:
- Pragmatic approach combining real and synthetic data
- All P0 and P1 tasks completed
- Zero-error ingestion pipeline
- Fast and reliable (288 samples/second)
- No external dependencies issues

ðŸŽ¯ **Current Status**:
- 2,324+ lyrics ingested
- 150+ music tracks generated
- 130+ songs created
- 14+ voice profiles available
- 2,343+ embeddings indexed
- RAG search operational

ðŸš€ **Ready for Production**:
- Stable ingestion pipeline
- Error handling in place
- Comprehensive logging
- Easy to use CLI
- Well-documented process
